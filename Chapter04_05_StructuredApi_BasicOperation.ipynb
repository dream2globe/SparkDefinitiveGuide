{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4. 구조적 API 기본 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Row 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=0), Row(id=1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.range(2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 5. 구조적 API 기본 연산\n",
    "+ DataFrame은 Row 타입의 <strong>레코드</strong>와 각 레코드에 수행할 연산 표현식을 나타내는 여러 <strong>컬럼</strong>으로 구성됨\n",
    "+ <strong>스키마</strong>는 각 컬럼명과 데이터 타입을 정의\n",
    "+ <strong>파티셔닝</strong>은 DataFrame이나 Dataset이 클러스터에서 물리적으로 배치되는 형태를 정의\n",
    "+ <strong>파티셔닝 스키마</strong>는 파이션을 배치하는 방법을 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 스키마 확인하기 \"\"\"\n",
    "df = spark.read.format(\"json\").load(\"./data/flight-data/json/2015-summary.json\") # 미국 교통통계국이 제공하는 항공운항 데이터\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 스키마\n",
    "+ 스키마는 여러 개의 StructField 타입 필드로 구성된 StructType 객체\n",
    "+ StructField는 이름, 데이터 타입, 컬럼이 값이 없거나 null일 수 있는지 지정하는 불리언 값을 가짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(DEST_COUNTRY_NAME,StringType,true),StructField(ORIGIN_COUNTRY_NAME,StringType,true),StructField(count,LongType,true)))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 스키마 구조 \"\"\"\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 스키마를 직접 만들어 적용 \"\"\"\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "\n",
    "myManualSchema = StructType([\n",
    "    StructField(\"DEST_COUNTRY_NAME\", StringType(), True),\n",
    "    StructField(\"ORIGIN_COUNTRY_NAME\", StringType(), True),\n",
    "    StructField(\"count\", LongType(), False, metadata={\"hello\":\"world\"})\n",
    "])\n",
    "\n",
    "df = spark.read.format(\"json\")\\\n",
    "    .schema(myManualSchema)\\\n",
    "    .load(\"./data/flight-data/json/2015-summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|            Grenada|   62|\n",
      "|       Costa Rica|      United States|  588|\n",
      "|          Senegal|      United States|   40|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 컬럼과 표현식\n",
    "+ DataFrame을 통하지 않으면 외부에서 컬럼에 접근 불가\n",
    "+ 컬럼의 내용을 수정하려면 반드시 DataFrame의 스파크 트랜포메이션을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 컬럼\n",
    "+ col, column 함수를 사용하는 것이 가장 간편\n",
    "+ 컬럼은 컬럼명을 카탈로그에 저장된 정보와 비교하기 전까지 미확인 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'someColumnName'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 컬럼 생성 \"\"\"\n",
    "from pyspark.sql.functions import col, column\n",
    "\n",
    "col(\"someColumnName\")\n",
    "column(\"someColumnName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 표현식\n",
    "+ <strong>표현식</strong>은 DataFrame 레코드의 여러 값에 대한 프랜스포메이션 집합을 의미\n",
    "+ 여러 컬럼명을 입력받아 식별하고 단일 값을 만들기 위해 다양한 표현식을 각 레코드에 적용하는 함수\n",
    "+ 표현식은 연 순서를 지정하는 논리적 트리로 컴파일됨\n",
    "+ 실행 시점에서 동일한 논리 트리로 컴파일되기 때문에 동일한 성능을 발휘함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'((((someCol + 5) * 200) - 6) < otherCol)'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 논리적 트리로 컴파일되는 표현식 \"\"\"\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "expr(\"(((someCol + 5) * 200) - 6) < otherCol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 프로그래밍 방식으로 컬럼에 접근할 때는 DataFrame의 columns 속성을 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEST_COUNTRY_NAME', 'ORIGIN_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" columns 속성을 사용 \"\"\"\n",
    "spark.read.format(\"json\").load(\"./data/flight-data/json/2015-summary.json\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 레코드와 로우\n",
    "+ 스파크는 레코드를 Row 객체로 표현\n",
    "+ Row 객체는 내부에 바이트 배열을 가지며, 오직 컬럼 표현식으로만 다룰 수 있으므로 사용자에게 노출되지 않음\n",
    "+ DataFrame을 사용해 드라이버에게 개별 로우를 반환하는 명령은 항상 하나 이상의 Row 타입을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Row를 확인하는 예문 \"\"\"\n",
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 로우 생성하기 \"\"\"\n",
    "from pyspark.sql import Row\n",
    "\n",
    "myRow = Row(\"Hello\", None, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 로우 접근하기 \"\"\"\n",
    "print(myRow[0])\n",
    "print(myRow[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 DataFrame의 트랜스포메이션\n",
    "#### 5.4.1 DataFrame 생성하기\n",
    "+ 원시 데이터소스에서 DataFrame을 생성하고 임시 뷰를 등록\n",
    "+ Row 객체를 가진 Seq 타입을 직접 전환하여 DataFrame을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 원시 데이터소스 활용 \"\"\"\n",
    "df = spark.read.format(\"json\")\\\n",
    "    .load(\"./data/flight-data/json/2015-summary.json\")\n",
    "df.createOrReplaceTempView(\"dfTable\")\n",
    "\n",
    "sql_result = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM dfTable\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "| some| col|names|\n",
      "+-----+----+-----+\n",
      "|Hello|null|    1|\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Row 객체 활용 \"\"\"\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "\n",
    "myManualSchema = StructType([\n",
    "    StructField(\"some\", StringType(), True),\n",
    "    StructField(\"col\", StringType(), True),\n",
    "    StructField(\"names\", LongType(), False)\n",
    "])\n",
    "\n",
    "myRow = Row(\"Hello\", None, 1)\n",
    "myDf = spark.createDataFrame([myRow], myManualSchema)\n",
    "myDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.2 select와 selectExpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|\n",
      "+-----------------+-------------------+\n",
      "|    United States|            Romania|\n",
      "|    United States|            Croatia|\n",
      "+-----------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 단일 혹은 다중 컬럼 설정 \"\"\"\n",
    "df.select(\"DEST_COUNTRY_NAME\").show(2)\n",
    "df.select(\"DEST_COUNTRY_NAME\", \"ORIGIN_COUNTRY_NAME\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+-----------------+\n",
      "|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|\n",
      "+-----------------+-----------------+-----------------+\n",
      "|    United States|    United States|    United States|\n",
      "|    United States|    United States|    United States|\n",
      "+-----------------+-----------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 컬럼을 참조하는 다앙한 방법 \"\"\"\n",
    "df.select(\n",
    "    expr(\"DEST_COUNTRY_NAME\"),\n",
    "    col(\"DEST_COUNTRY_NAME\"),\n",
    "    column(\"DEST_COUNTRY_NAME\")\n",
    ").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|  destination|\n",
      "+-------------+\n",
      "|United States|\n",
      "|United States|\n",
      "+-------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" expr를 이용한 컬럼 참조 \"\"\"\n",
    "df.select(expr(\"DEST_COUNTRY_NAME AS destination\")).show(2)\n",
    "df.select(expr(\"DEST_COUNTRY_NAME AS destination\").alias(\"DEST_COUNTRY_NAME\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ select메서드에 expr 함수를 사용하는 패턴을 자주 사용함\n",
    "+ 스파크는 이를 위해 selectExpr 메서드를 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "| newColmnName|DEST_COUNTRY_NAME|\n",
      "+-------------+-----------------+\n",
      "|United States|    United States|\n",
      "|United States|    United States|\n",
      "+-------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" selectExpr 활용 예문 \"\"\"\n",
    "df.selectExpr(\"DEST_COUNTRY_NAME as newColmnName\", \"DEST_COUNTRY_NAME\").show(2)\n",
    "df.selectExpr(\"*\", \"(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) as withinCountry\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------------------+\n",
      "| avg(count)|count(DISTINCT DEST_COUNTRY_NAME)|\n",
      "+-----------+---------------------------------+\n",
      "|1770.765625|                              132|\n",
      "+-----------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 집계함수 지정하기 \"\"\"\n",
    "df.selectExpr(\"avg(count)\", \"count(distinct(DEST_COUNTRY_NAME))\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.3 스파크 데이터 타입으로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|One|\n",
      "+-----------------+-------------------+-----+---+\n",
      "|    United States|            Romania|   15|  1|\n",
      "|    United States|            Croatia|    1|  1|\n",
      "+-----------------+-------------------+-----+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 리터럴(literal)을 사용한 컬럼 추가 \"\"\"\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df.select(expr(\"*\"), lit(1).alias(\"One\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.4 컬럼 추가하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|numberOne|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "|    United States|            Romania|   15|        1|\n",
      "|    United States|            Croatia|    1|        1|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" withColumn으로 컬럼 추가 \"\"\"\n",
    "df.withColumn(\"numberOne\", lit(1)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 컬럼 비교 \"\"\"\n",
    "df.withColumn(\"withinCountry\", expr(\"ORIGIN_COUNTRY_NAME == DEST_COUNTRY_NAME\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEST_COUNTRY_NAME', 'ORIGIN_COUNTRY_NAME', 'count', 'Destination']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 컬럼명 바꾸기 \"\"\"\n",
    "df.withColumn(\"Destination\", expr(\"DEST_COUNTRY_NAME\")).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.5 컬럼명 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dest', 'ORIGIN_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" withColumnRenamed \"\"\"\n",
    "df.withColumnRenamed(\"DEST_COUNTRY_NAME\", \"dest\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.6 예약 문자와 키워드\n",
    "+ 공백이나 하이픈(-) 같은 예약 문자를 컬럼명에 사용하려면 백틱(`) 문자를 사용해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---------------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|This Long Column-Name|\n",
      "+-----------------+-------------------+-----+---------------------+\n",
      "|    United States|            Romania|   15|              Romania|\n",
      "|    United States|            Croatia|    1|              Croatia|\n",
      "+-----------------+-------------------+-----+---------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---------------------+-------+\n",
      "|This Long Column-Name|new col|\n",
      "+---------------------+-------+\n",
      "|              Romania|Romania|\n",
      "|              Croatia|Croatia|\n",
      "+---------------------+-------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---------------------+\n",
      "|This Long Column-Name|\n",
      "+---------------------+\n",
      "|              Romania|\n",
      "|              Croatia|\n",
      "+---------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" withColumn, selectExpr, select 차이점 \"\"\"\n",
    "dfWithLongColName = df.withColumn(\"This Long Column-Name\", expr(\"ORIGIN_COUNTRY_NAME\")) # 첫 번째 인수에서 사용하지 않음\n",
    "dfWithLongColName.show(2)\n",
    "\n",
    "dfWithLongColName.selectExpr(\"`This Long Column-Name`\", \"`This Long Column-Name` as `new col`\").show(2) # 사용함\n",
    "\n",
    "dfWithLongColName.select(expr(\"`This Long Column-Name`\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.7 대소문자 구분\n",
    "+ 기본적으로 스파크는 대소문자를 가리지 않음\n",
    "```\n",
    "set spark.sql.caseSensitive true # 대소문자를 구분하기 위한 옵션\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.8 컬럼 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['count', 'This Long Column-Name']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" drop 함수 \"\"\"\n",
    "\n",
    "df.drop(\"ORIGIN_COUNTRY_NAME\").columns\n",
    "dfWithLongColName.drop(\"ORIGIN_COUNTRY_NAME\", \"DEST_COUNTRY_NAME\").columns # 여러 컬럼을 지우기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.9 컬럼의 데이터 타입 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint, count2: string]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" cast 함수 \"\"\"\n",
    "df.withColumn(\"count2\", col(\"count\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.10 로우 필터링하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" filter, where 함수 \"\"\"\n",
    "df.filter(col(\"count\") < 2).show(2)\n",
    "df.where(col(\"count\") < 2).show(2) # 동일한 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|          Singapore|    1|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 같은 표현식에 여러 필터를 적용 \"\"\"\n",
    "df.where(col(\"count\") < 2).where(col(\"ORIGIN_COUNTRY_NAME\") != \"Croatia\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.11 고유한 로우 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "\"\"\" distinct 함수 \"\"\"\n",
    "print(df.select(\"ORIGIN_COUNTRY_NAME\", \"DEST_COUNTRY_NAME\").distinct().count())\n",
    "print(df.select(\"ORIGIN_COUNTRY_NAME\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.12 무작위 샘플 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" sample 함수 \"\"\"\n",
    "seed = 5\n",
    "withReplacement = False\n",
    "fraction = 0.5\n",
    "df.sample(withReplacement, fraction, seed).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.13 임의 분할하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" randomSplit 함수 \"\"\"\n",
    "dataFrames = df.randomSplit([0.25, 0.75], seed)\n",
    "dataFrames[0].count() > dataFrames[1].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.14 로우 합치기와 추가하기\n",
    "+ 동일한 스키마와 컬럼 수를 가져야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|      New Country|      Other Country|    5|\n",
      "|    New Country 2|    Other Country 3|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|          Gibraltar|    1|\n",
      "|    United States|             Cyprus|    1|\n",
      "|    United States|            Estonia|    1|\n",
      "|    United States|          Lithuania|    1|\n",
      "|    United States|           Bulgaria|    1|\n",
      "|    United States|            Georgia|    1|\n",
      "|    United States|            Bahrain|    1|\n",
      "|    United States|   Papua New Guinea|    1|\n",
      "|    United States|         Montenegro|    1|\n",
      "|    United States|            Namibia|    1|\n",
      "|    New Country 2|    Other Country 3|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" union 함수 \"\"\"\n",
    "from pyspark.sql import Row\n",
    "\n",
    "schema = df.schema\n",
    "newRows = [\n",
    "    Row(\"New Country\", \"Other Country\", 5),\n",
    "    Row(\"New Country 2\", \"Other Country 3\", 1)\n",
    "]\n",
    "\n",
    "# Parallelized Collections :\n",
    "# Parallelized collections are created by calling SparkContext’s parallelize method on an existing iterable or collection in your driver program.\n",
    "# The elements of the collection are copied to form a distributed dataset that can be operated on in parallel. \n",
    "\n",
    "parallelizedRows = spark.sparkContext.parallelize(newRows) \n",
    "newDF = spark.createDataFrame(parallelizedRows, schema)\n",
    "\n",
    "newDF.show()\n",
    "\n",
    "df.union(newDF)\\\n",
    "    .where(\"count = 1\")\\\n",
    "    .where(col(\"ORIGIN_COUNTRY_NAME\") != \"United States\")\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.15 로우 정렬하기\n",
    "+ asc, desc 함수를 사용하여 정렬 순서를 지정\n",
    "+ asc_nulls_first, desc_nulls_first, asc_nulls_last, desc_nulls_last 메서드로 null의 정렬 순서를 지정\n",
    "+ sortWithinPartitions 함수는 파티션별 정렬을 지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|               Malta|      United States|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|          Gibraltar|    1|\n",
      "|       United States|          Singapore|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|     Burkina Faso|      United States|    1|\n",
      "|    Cote d'Ivoire|      United States|    1|\n",
      "|           Cyprus|      United States|    1|\n",
      "|         Djibouti|      United States|    1|\n",
      "|        Indonesia|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|     Burkina Faso|      United States|    1|\n",
      "|    Cote d'Ivoire|      United States|    1|\n",
      "|           Cyprus|      United States|    1|\n",
      "|         Djibouti|      United States|    1|\n",
      "|        Indonesia|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" sort, orderBy 함수 \"\"\"\n",
    "df.sort(\"count\").show(5)\n",
    "df.orderBy(\"count\", \"DEST_COUNTRY_NAME\").show(5)\n",
    "df.orderBy(col(\"count\"), col(\"DEST_COUNTRY_NAME\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|               Malta|      United States|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|          Gibraltar|    1|\n",
      "|       United States|          Singapore|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Vietnam|    2|\n",
      "|    United States|          Venezuela|  246|\n",
      "|    United States|            Uruguay|   13|\n",
      "|          Algeria|      United States|    4|\n",
      "|           Angola|      United States|   15|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 정렬순서 지정하기 \"\"\"\n",
    "from pyspark.sql.functions import desc, asc\n",
    "\n",
    "df.orderBy(expr(\"count desc\")).show(5)\n",
    "df.orderBy(col(\"ORIGIN_COUNTRY_NAME\").desc(), col(\"DEST_COUNTRY_NAME\").asc()).show(5) # 예제 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['count ASC NULLS FIRST], false\n",
      "+- Relation[DEST_COUNTRY_NAME#616,ORIGIN_COUNTRY_NAME#617,count#618L] json\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint\n",
      "Sort [count#618L ASC NULLS FIRST], false\n",
      "+- Relation[DEST_COUNTRY_NAME#616,ORIGIN_COUNTRY_NAME#617,count#618L] json\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [count#618L ASC NULLS FIRST], false\n",
      "+- Relation[DEST_COUNTRY_NAME#616,ORIGIN_COUNTRY_NAME#617,count#618L] json\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Sort [count#618L ASC NULLS FIRST], false, 0\n",
      "+- *(1) FileScan json [DEST_COUNTRY_NAME#616,ORIGIN_COUNTRY_NAME#617,count#618L] Batched: false, Format: JSON, Location: InMemoryFileIndex[file:/home/jovyan/work/SparkDefinitiveGuide/data/flight-data/json/2013-summary...., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:bigint>\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 파티션별 정렬 \"\"\" \n",
    "# 최적화는 3부에서 자세히 소개할 예정\n",
    "spark.read.format(\"json\").load(\"./data/flight-data/json/*-summary.json\").sortWithinPartitions(\"count\").explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.16 로우 수 제한하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "\n",
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|               Malta|      United States|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|          Gibraltar|    1|\n",
      "|       United States|          Singapore|    1|\n",
      "|             Moldova|      United States|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(5).show()\n",
    "df.orderBy(expr(\"count desc\")).limit(6).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.17 repartition과 coalesce\n",
    "+ 향후에 사용할 파티션 수가 현재 파티션 수보다 많거나 컬럼을 기준으로 파티션을 만드는 경우에 사용(repartition, 셔플이 필수로 발생)\n",
    "+ 자주 필터링되는 컬럼을 기준으로 파티션 재분배를 권장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 파티션 나누기 \"\"\"\n",
    "df.rdd.getNumPartitions()\n",
    "df.repartition(5)\n",
    "df.repartition(col(\"DEST_COUNTRY_NAME\"))\n",
    "df.repartition(5, col(\"DEST_COUNTRY_NAME\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 셔플하지 않고 파티션을 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 파티션 합치기 \"\"\"\n",
    "df.repartition(5, col(\"DEST_COUNTRY_NAME\")).coalesce(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.18 드라이버로 로우 데이터 수집하기\n",
    "+ 대규모 데이터셋에 collect 명령을 수행하면 드라이버 비정상 종료 우려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |15   |\n",
      "|United States    |Croatia            |1    |\n",
      "|United States    |Ireland            |344  |\n",
      "|Egypt            |United States      |15   |\n",
      "|United States    |India              |62   |\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344),\n",
       " Row(DEST_COUNTRY_NAME='Egypt', ORIGIN_COUNTRY_NAME='United States', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='India', count=62)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectDF = df.limit(5)\n",
    "collectDF.take(5) # 정수를 인수값으로 사용\n",
    "collectDF.show()  # 결과를 정돈된 형태로 출력\n",
    "collectDF.show(5, False)\n",
    "collectDF.collect() # 전체 모든 테이터를 수집"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
